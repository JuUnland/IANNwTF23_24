{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_digits\n",
        "from sklearn.model_selection import train_test_split\n",
        "from matplotlib import pyplot as plt\n",
        "import numpy as np\n",
        "import math"
      ],
      "metadata": {
        "id": "76WTYlPzuLzo"
      },
      "execution_count": 144,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "digits = load_digits()\n",
        "minibatchsize = 5\n",
        "target_size = len(digits.target_names)\n",
        "print(target_size)\n",
        "\n",
        "X = np.array(digits.data)\n",
        "y = np.array(digits.target)\n",
        "\n",
        "# scaling the numbers\n",
        "X = (X - np.min(X))/(np.max(X)-np.min(X))\n",
        "\n",
        "# float 64 shoudl be fine aswell\n",
        "print(X.dtype)\n",
        "\n",
        "# encoding into one hot vectors\n",
        "y = np.eye(target_size)[y]\n",
        "\n",
        "# helper function to confirm correct splitting\n",
        "def show_img(digits):\n",
        "  plt.gray()\n",
        "  plt.matshow(digits.reshape(8, 8))\n",
        "  plt.show()\n",
        "\n",
        "# yield X, y randomly\n",
        "def shuffle_generator(X, y, minibatchsize=minibatchsize):\n",
        "  shuffler = np.random.permutation(len(X))\n",
        "  X = X[shuffler]\n",
        "  y = y[shuffler]\n",
        "  start_index = 0\n",
        "\n",
        "  while start_index + minibatchsize < len(X):\n",
        "    yield(X[start_index:start_index+minibatchsize], y[start_index:start_index+minibatchsize])\n",
        "    start_index += minibatchsize"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I2y5RTM9uL-3",
        "outputId": "11e5eb49-dd07-4c1a-f811-7228f35afc75"
      },
      "execution_count": 153,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10\n",
            "float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class sigmoid_function():\n",
        "  # minibatchsize, 64\n",
        "  def __call__(self, input : np.ndarray):\n",
        "    out = 1/(1 + np.exp(-input))\n",
        "    return out\n",
        "\n",
        "  # preactivation: (minibatch_size, num_units)\n",
        "  def backwards(preactivation, activation, error):\n",
        "    # calculate: dL/d_preactivation\n",
        "    pass\n",
        "\n",
        "\n",
        "class softmax():\n",
        "  # minibatchsize, 10\n",
        "  def __call__(self, input : np.ndarray):\n",
        "    output = np.ndarray(shape=(minibatchsize, target_size), dtype=float)\n",
        "    for idx, batch in enumerate(input):\n",
        "      sum = np.sum(np.exp(batch))\n",
        "      out = np.exp(batch) / sum\n",
        "      output[idx] = out\n",
        "    return output\n",
        "\n",
        "class cross_entropy():\n",
        "  # beide 10 groß\n",
        "  def __call__(y_true : np.ndarray, y_pred : np.ndarray):\n",
        "    return -np.sum(y_true * np.log(y_pred + 10**-100))\n",
        "\n",
        "  def backwards(prediction : np.ndarray, target : np.ndarray, loss : float):\n",
        "    return prediction - target\n",
        "\n",
        "\n",
        "act_fct = sigmoid_function()\n",
        "soft = softmax()\n",
        "gen = shuffle_generator(X, y)\n",
        "\n",
        "X_batch, y_batch = next(gen)\n",
        "\n",
        "print(y_batch)\n",
        "\n",
        "act_X = act_fct(X_batch)\n",
        "sof_y = soft(y_batch)\n",
        "\n",
        "print(sof_y.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VCiwxUPv8PHk",
        "outputId": "e850f9bc-bab0-4b3d-ede4-682407f22daf"
      },
      "execution_count": 173,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
            " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
            "(5, 10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import List\n",
        "\n",
        "class MLP_layer():\n",
        "  def __init__(self, activation_function : any, units : int, input_size : int):\n",
        "    self.activation_function = activation_function\n",
        "    self.units = units\n",
        "    self.input_size = input_size\n",
        "    self.weights = np.random.normal(0, 0.2, size=(units, input_size))\n",
        "    self.bias = np.zeros(units)\n",
        "\n",
        "  def forward(self, input : np.ndarray):\n",
        "    output = np.ndarray(shape=(minibatchsize, self.units), dtype=float)\n",
        "\n",
        "    for idx, input in enumerate(input):\n",
        "      new_unit_values = self.weights @ input\n",
        "      output[idx] = new_unit_values\n",
        "\n",
        "    output = output - self.bias\n",
        "    output = self.activation_function(output)\n",
        "    return output\n",
        "\n",
        "class ANN():\n",
        "  def __init(self):\n",
        "    layer1 = MLP_layer(sigmoid_function(), 32, 64)\n",
        "    layer2 = MLP_layer(sigmoid_function(), 16, 32)\n",
        "    layer3 = MLP_layer(softmax(), 10, 16)\n",
        "    self.layers = [layer1, layer2, layer3]\n",
        "\n",
        "# Implement the backwards function for your CCE object: It expects at least\n",
        "# the inputs prediction (our ˆy) of shape (minibatch size,10), and loss (our LCCE of\n",
        "# shape (minibatch size,1), i.e. one loss per minibatch element. It should return\n",
        "# a respective matrix of shape (minibatch size,1) representing the error signal\n",
        "# (think in Leibnitz notation: The derivative calculated up to this step).\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "print(output1)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C5p_dRKHBxuM",
        "outputId": "081e94a6-843a-4275-ba51-019e47e0878f"
      },
      "execution_count": 185,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.70968288 0.67193585 0.60429279 0.42634499 0.30809749 0.58250221\n",
            "  0.42753085 0.57189351 0.52548654 0.38878332 0.21356587 0.52279922\n",
            "  0.75422911 0.80538153 0.38797798 0.39687768 0.20465349 0.57146999\n",
            "  0.5456352  0.39139718 0.4952512  0.68851924 0.56431047 0.42988551\n",
            "  0.77647086 0.49822981 0.42725605 0.68478528 0.40847654 0.46694883\n",
            "  0.59594611 0.58653055]\n",
            " [0.72616556 0.68784906 0.42248407 0.52007674 0.1883039  0.46374787\n",
            "  0.36625387 0.3497367  0.57676841 0.41630507 0.26909414 0.62756116\n",
            "  0.65282495 0.86173109 0.27560076 0.24702721 0.46872244 0.66395392\n",
            "  0.59375255 0.55514425 0.5002546  0.61099833 0.33683589 0.42382507\n",
            "  0.71682994 0.51722408 0.5194866  0.84695919 0.34750508 0.45804091\n",
            "  0.52847793 0.44754943]\n",
            " [0.58971917 0.64002387 0.74114231 0.56033035 0.39978236 0.68775009\n",
            "  0.51179405 0.57131789 0.61633504 0.25508806 0.1491633  0.53552062\n",
            "  0.79221174 0.72838516 0.33866816 0.39781363 0.18467192 0.76450513\n",
            "  0.65781593 0.37633224 0.54319054 0.70945722 0.69126984 0.62741751\n",
            "  0.46388512 0.61349158 0.30756062 0.39528736 0.47780587 0.51171693\n",
            "  0.51265227 0.70788655]\n",
            " [0.44074125 0.74059491 0.60446479 0.41032616 0.28734909 0.51742788\n",
            "  0.52452795 0.60744384 0.49725746 0.31798321 0.16294756 0.42097205\n",
            "  0.77141193 0.76198872 0.29836501 0.36356406 0.3732002  0.64753534\n",
            "  0.62763847 0.40190046 0.55596994 0.59232614 0.5704384  0.44201562\n",
            "  0.49905909 0.60803585 0.38452112 0.50083079 0.36754729 0.47752626\n",
            "  0.40994968 0.5613139 ]\n",
            " [0.63635373 0.63272991 0.55244853 0.37348963 0.30899677 0.64693135\n",
            "  0.47182866 0.6633064  0.54839168 0.33532976 0.24602003 0.58817957\n",
            "  0.73477278 0.7975747  0.38507265 0.38135791 0.21426094 0.56925537\n",
            "  0.58685313 0.40325253 0.62025898 0.63294114 0.6283325  0.39738296\n",
            "  0.75430743 0.57063494 0.34889879 0.68585549 0.37599302 0.35513131\n",
            "  0.58564886 0.59459003]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "l2-oofTuKco5"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}